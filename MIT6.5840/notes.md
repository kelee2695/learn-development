# 6.5840 分布式系统
## Lecture 0
### 分布式系统概念
一个分布式系统是由多个独立的计算机（通常称为节点，Node）​​ 组成的集合，这些节点通过网络连接和消息传递进行通信与协调，从而对外作为一个统一的、连贯的系统提供服务或完成共同的任务。
### 分布式系统内涵
![分布式系统内涵](picture/distributed_system.png "分布式系统内涵")
分布式系统的世界远不止于“计算”。它是一个丰富的工具箱，提供了各种模式来解决不同维度的问题：
​解决资源问题​：用 ​分布式资源（IaaS）​​
​解决算力问题​：用 ​分布式计算（Hadoop）​​
​解决复杂度问题​：用 ​分布式协作（微服务）​​
​解决数据存储规模问题​：用 ​分布式数据（Database）​​
​解决网络效率与信任问题​：用 ​分布式网络（CDN/区块链）​​
​解决AI数据隐私和规模问题​：用 ​分布式智能（联邦学习，大模型分布式训练，分布式推理）​​
​解决多用户互动问题​：用 ​分布式应用（协作工具/游戏）​​
所有这些都共享着分布式系统的核心思想：​通过消息传递，让多个独立的组件协同工作，从而达成一个共同的目标，并以此获得单机系统无法比拟的优势。
#### KVM等虚拟化技术在此体系中的地位
KVM等虚拟化技术可将物理主机一虚多，主要用于提供虚拟化的服务器节点（服务器节点可组成分布式系统）。使用这种虚拟化技术管理，可以解决分布式资源的问题。
#### k8s在此体系中的地位
k8s不属于上述任何一个维度，k8s是一个使用分布式的资源（服务器node集群提供的分布式资源，其中服务器node集群可以是物理机，也可以是IaaS提供的虚拟机集群）构建分布式系统（由多个pod组成的分布式系统）的管理平台。
#### 分而治之
分而治之是分布式系统的核心思想，它将一个复杂的问题分解为多个简单的问题，每个问题都可以在分布式系统中的一个节点上解决。分了之后将分得到的结果合起来作为结果提供。
在分布式资源中，每个节点分开执行虚拟化操作，将虚拟化之后的资源合成大资源池，为用户提供分布式系统貌似整体的服务。最后以虚拟机的形式为用户提供主机节点。从这个角度来看，KVM等虚拟化技术可以被看作一种分布式资源。
分布式网络，将用户复杂的网络资源请求，分散到不同的节点上，每个节点负责处理一部分请求。最后将每个节点处理的结果合并起来，提供给用户。
分布式计算，将用户复杂的计算任务，分散到不同的节点上，每个节点负责处理一部分任务。最后将每个节点处理的结果合并起来，提供给用户。
## Lecture 1 
### 1. MapReduce分布式计算框架
Hadoop 是一个使用分布式系统实现分布式计算的框架。是使用 Java 编写，允许分布在集群，使用简单的编程模型的计算机大型数据集处理的Apache 的开源框架。其主要的计算框架是 MapReduce。
MapReduce 是一个分布式运算程序的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。 MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。
#### 用户角度
用户角度需要实现map与reduce两个函数。
map函数：将输入的key-value对映射为中间的key-value对列表。
reduce函数：将具有相同key的中间的key-value对列表归并为输出的key-value对。
在map函数中，输入的键值对为原始数据，中间键值对是map函数对原始数据进行了一定的计算，并对计算结果进行了分类。其中分类就是中间键值对的键。分类指定该计算结果由哪一个reduce函数处理。
在reduce函数中，输入的键值对列表是map函数输出的中间键值对列表中，键相同的那些键值对。reduce函数需要将这些键值对进行归并，输出为最终的键值对。最终的键值对的键，也是map函数分类产生的键。（因为reduce函数会对每一个map出的类生成一个结果。）
上述论证意味着，mapreduce框架的设计过程为：
1. 将大段的、无头绪的数据转化为一条一条的记录。（如大量文本转化为一条一条的词频，大量请求记录转化为一条一条的请求记录）
2. 其中一条一条的概念是指每一个中间键值对的组（以键分组）生成一条数据。
3. map函数用于从原始数据得到中间键值对。
4. reduce函数用于从中间键值对列表得到最终的键值对。
#### mapreduce开发人员角度
![mapreduce工作流程](picture/mapreduce_process.jpg "mapreduce工作流程")
要实现一个可用的 MapReduce 框架，需要设计和实现以下几个核心组件：
##### ​Master/JobTracker（作业调度与资源管理）​​
这是框架的大脑，负责全局管理。你需要实现：
​作业管理​：接收客户端提交的作业，将其分解为具体的 Map 任务和 Reduce 任务。
​任务调度​：监控各个 Worker（TaskTracker）的状态，将任务分配给空闲的 Worker，并尽可能遵循数据本地化原则，即优先将任务分配给存有对应数据块的 Worker，以减少网络传输。
​容错处理​：通过心跳机制监控 Worker 的健康状态。如果某个 Worker 失效，Master 需要将其负责的任务重新调度到其他健康的 Worker 上执行。
##### ​Worker/TaskTracker（任务执行器）​​
这是框架的四肢，负责执行具体的计算任务。每个 Worker 需要：
​汇报状态​：定期向 Master 发送心跳，报告自身状态和任务执行进度。
​执行任务​：根据 Master 的指令，启动独立的进程或线程来执行 Map 任务或 Reduce 任务。
​数据管理​：Map 任务会从分布式文件系统（如 HDFS）读取输入数据分片；Reduce 任务将最终结果写回分布式文件系统。
##### 编程模型接口​
为了让用户能够定义业务逻辑，你需要提供清晰的编程接口：
​Mapper 接口​：用户继承此类并实现 map方法，处理输入的键值对并生成中间结果。
​Reducer 接口​：用户继承此类并实现 reduce方法，对属于同一个 key 的所有中间值进行聚合。
##### 关键流程与技术难点
在实现上述组件时，​Shuffle​ 阶段是最复杂也是最核心的部分，它连接了 Map 和 Reduce，具体包括：
​Map 端 Shuffle​：
​分区（Partitioning）​​：Map 输出的每个键值对会根据一个分区函数（默认是 Hash 分区）确定它属于哪个 Reduce 任务。
​排序（Sorting）​​：每个分区内的数据会按照 key 进行排序，为后续 Reduce 端的归并做准备。
​合并（Combiner）​​：这是一个可选的本地聚合优化，在 Map 端先对中间结果进行一次合并，可以显著减少网络传输的数据量。
​Reduce 端 Shuffle​：
​数据拉取（Fetch）​​：Reduce 任务启动线程，从各个已完成 Map 任务的节点上拉取属于自己分区的数据。
​归并排序（Merge Sort）​​：由于数据来自多个 Map 任务，Reduce 任务需要将这些数据文件进行归并，最终形成一个有序的大文件，然后才开始执行用户定义的 Reduce 函数。
### MapReduce: Simplified Data Processing on Large Clusters论文阅读
#### 摘要
MapReduce是一种编程模型，用于处理大型数据集。用户指定一个映射函数，该函数处理输入键值对生成一组中间键值对，指定一规约函数，合并所有与同一中间键相关联的中间值，生成最终的键值对。
使用这种风格编写的呈现会自动并行化，在大量的集群机器上并行执行，最后合并结果。
#### 简介
map实现的是将输入数据对应输出数据进行分组，reduce实现处理分组后的数据得到对应的结果。
1. 第二节描述了基本的编程模型。
2. 第三节介绍针对特定集群环境定制的MapReduce接口实现。
3. 第四节描述了认为有用的编程模型的改进。
4. 第五节描述了针对各种任务实现的性能测量结果。
5. 第六节描述了MapReduce在谷歌内部的使用。
6. 第七节讨论了相关工作与未来工作。
#### 编程模型
MapReduce解决的问题为由一个键值对序列生成另一个键值对序列。
举例（统计单词出现的次数）：由[(文件名1，文件内容1)，(文件名2，文件内容2)……]----->[(单词1，出现次数1)，(单词2，出现次数2)……]
map函数的功能为将输入的键值对映射为中间键值对。
reduce函数的功能为将中间键值对列表归并为最终的键值对。
其过程如下图：
![mapreduce编程模型](picture/mapreduce编程模型.png "mapreduce编程模型")
#### 实施
MapReduce接口由多种实现方式，正确选择实现方式取决于环境。
论文举三例：
1. 适用于小型共享内存。
2. 适用于大型非同一内存访问（NUMA）多处理器。
3. 适用于大规模的联网集群集群。
详细描述了针对谷歌广泛使用的大规模联网机器集群的MapReduce实现。
##### 该MapReduce程序执行过程
1. 将输入文件分割为M个大小通常为64MB的输入分片。
2. 在一组机器上启动多个数据Mapreduce程序副本。
3. 在这些程序副本中，有一份副本比较特殊，称为主节点副本，其余的节点为工作节点，主节点会在工作节点上分配M个Map任务和R个reduce任务。主节点挑选空闲的工作节点，并为每一个工作节点分配一个映射任务或者一个归约任务。
4. 映射任务的工作节点会读取数据分片，解析成所有传递给自己的键值对，然后调用用户定义的Map函数，生成中间值键值对，此时生成的中间值键值对会在内存中缓冲。
5. 缓冲区中的中间键值对会被定期写入本机磁盘中（本机磁盘属于分布式存储系统的成员）。本机会将磁盘中的中间键值对基于键划分为R个区域，对应R个归约任务。这R个区域在磁盘中的位置会被汇报给主节点，主节点会将这些位置信息发送给对应的归约任务。
6. 当一个归约工作节点从主节点收到这些数据的位置时，会通过远程过程调用的形式从对应的Map工作节点上拉取所有属于自己的数据块，当一个归约节点拉去到自己所有的数据后，会按照中间键对其进行排序（不同中间键可能会被映射到同一个归约节点，排序可以让相同的键归为一组）。
7. 归约工作进程会对排列后的中间数据进行迭代，对于每一个唯一的中间键，会将该键与中间值序列传入归约函数。函数输出会被最佳到此归约分区的最终输出文件中。
8. 所有任务完成后会返回。
##### 执行过程中所需数据结构
1. 每个Map任务与Reduce任务的状态。
2. 每个工作节点具体的身份，是哪一个Map或哪一个Reduce。
3. 主节点是映射任务结果传递到规约任务的通路，因此主节点维护着每一个映射认为R个中间文件区域的位置与大小，当Map任务完成后，会通知主节点更新中间文件区域位置与大小信息，然后会将更新后的信息结构体推送给归约任务。
##### 容错性设计
###### 工作节点故障：
1. 节点故障的判定：工作节点会周期性的给主节点发送心跳信号，如果主节点在一定时间内没有收到工作节点的心跳信号，就会将该工作节点判定为故障节点。
2. 此时工作节点上已经完成的Map任务会被重置为空闲，使得其可以被重新调度。因为Map任务的结果存储于本地磁盘，当工作节点故障时，这些结果会丢失。此后执行规约任务的节点都会被定向到新的Map节点读取Map的结果。
3. 此时工作节点上已经完成的归约任务不会受到影响，因为归约任务的结果作为输出存储在全局文件系统中，不会因为一个节点的故障造成输出结果的丢失。
4. 正在执行的任何映射任务与归约任务都会被重置为空闲状态，等待重新调度。
###### 主节点故障：
1. 如果主节点出现故障，将停止MapReduce的计算，用户可以查看到这种情况如有必要，可以重启MapReduce计算。
2. 主节点的错误处理可以通过主节点定期记录主节点中的数据结构实现，便于根据检查点重启主节点。
###### 故障存在的语义学：
1. 当用户提供的映射函数与归约函数是输入值的确定性函数时，存在错误与不存在错误，整个系统产生的结果是相同的。
2. 系统通过原子提交的方式实现这个特性，每一个任务都会且仅会提交一个任务结果。Map任务在运行时持有R个私有数据结果，在Map任务完全完成后，会将这R个数据区的信息传递给Master节点。Reduce任务在运行时会持有1个私有数据结果，在Reduce任务完全完成后，会将这个数据结果存储进入分布式的数据存储系统中。
##### 本地性
鉴于网络带宽的稀缺性，MapReduce程序在执行时，会尽可能地将数据本地化处理，即尽可能地将数据处理在数据所在的机器上，而不是将数据传输到处理节点上。这一特性采用了GFS的文件分布策略，该分布式文件系统将文件分为64Mb的快，并在不同的机器上存储每一个块的多个副本，通常为三个副本。Master节点在进行任务调度时，会考虑到文件位置信息，将任务调度到数据所在节点或与数据接近的节点上。
###### GFS：
1. GFS是一个分布式文件系统，文件存储于多个机器上，为用户提供集中的文件存储读取服务。
2. GFS的文件分布在集群机器上，同时提供副本进行容错及可靠性保证。例如客户端写入读取文件的直接操作都是分布在集群各个机器上的，没有单点性能压力。
##### 任务粒度：
将整个分布式任务细分为多个细粒度的任务是MapReduce实现高性能计算的基础。其中映射任务会被细分为M个任务，规约任务会被细分为R个任务。理想情况下M和R应该远大于工作机器的数量。让每个工作集群执行许多不同的任务有助于实现动态负载均衡（任务的细碎便于分配，若任务太过整且大会导致有些节点还没处理完自己的任务，但是有些节点已经处于空闲）。
M、R的大小存在实际的限制，因为主节点需要做出O（M+R）次决策，并且在上述内存中保留这O（M+R）个任务状态。同时R会受到用户的限制。
##### 备份任务
当MapReduce任务接近完成时，会为每个未完成的任务创建一个备份任务，以防止任务失败导致整个计算过程失败。当任务的任何一个备份或主任务完成后，会将该任务标记为已完成，主节点会根据任务状态更新任务状态。
#### 改进措施
//////////////////////////////
### 2. 分布式文件系统HDFS
#### 分布式文件系统的定义
使用分布式系统进行文件存储，文件存储于不同的机器上，为用户提供集中的文件存储读取服务的系统都是分布式文件系统，传统的网络文件系统（NFS）也是分布式文件系统，但是文件只存储于单机，无可靠性保证。
#### HDFS分布式文件系统
HDFS，是Hadoop Distributed File System的简称，是Hadoop项目中实现的一种分布式文件系统。
HDFS的文件分布在集群机器上，同时提供副本进行容错及可靠性保证。例如客户端写入读取文件的直接操作都是分布在集群各个机器上的，没有单点性能压力。
HDFS 由​NameNode与DataNode组成，NameNode 负责管理文件系统的命名空间​（Namespace），如文件的目录结构、权限信息，以及记录每个文件由哪些数据块组成、这些数据块分布在哪些 DataNode 上。​DataNode​是实际存储数据块的工作节点。它们负责处理文件系统客户端的读写请求，执行数据块的创建、删除和复制等操作。
DataNode 会定期向 NameNode 发送心跳信号​（Heartbeat）和块报告​（Block Report），以汇报自身健康状况和存储的数据块列表。NameNode 依此判断 DataNode 是否存活以及数据块的状态。
##### HDFS ​数据上传流程​
客户端将文件分块后，从 NameNode 获取存储位置，并通过管道式写入将数据块传输至多个 DataNode 完成存储和副本复制。
##### HDFS ​数据下载流程​
客户端从 NameNode 获取文件元数据（包含数据块位置），然后并行从多个 DataNode 读取数据块，最终在本地组装成完整文件。
##### HDFS优势
1. HDFS 通过数据分块和多副本机制实现容错。文件被切分成块（默认128MB），每个块复制多个副本（默认3个）并分布在不同节点甚至不同机架上。
2. HDFS 优化了大规模数据的批量读写吞吐率，具有文件分块存储的特点，不存在单点性能压力。
### YARN
YARN ：是 Hadoop 2.0 引入的资源管理和作业调度系统。它将 Hadoop 集群的资源（如 CPU、内存）抽象为统一的资源池，并负责管理和分配这些资源给运行在集群上的应用程序。
### Lab1

